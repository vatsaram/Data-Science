library(twitteR)
require("twitteR")
consumer_key    = 'SJeBNqqHTcjwg7PhWGYHljuvf'
consumer_secret = 'ZDauLdKLqBR5yWsG79jZsDjfABPm63eDknRL27h7OfoBS5IkT'
access_token    = '1035066840005787648-N1702KVt51nYA9s3f02RD51KkM2pOw'
access_secret   = 'eGD9Db6oqR8UklZkoitVofekG7ZJDvx00ni0jKMwJvYYU'
download.file(url="http://curl.haxx.se/ca/cacert.pem",destfile="cacert.pem")
twitteR:::setup_twitter_oauth(consumer_key,consumer_secret,access_token,access_secret)
#Fetch Wikipedia
library(devtools)
install.packages("devtools")
#Fetch Wikipedia
library(devtools)
install_github("Ironholds/WikipediR")
library(WikipediR)
library(tm.plugin.webmining)
install.packages("tm.plugin.webmining")
library(tm.plugin.webmining)
library(stringr)
#Get Wikipedia content
wp_content <- page_content("en","wikipedia",
page_name = "India_national_cricket_team")
View(wp_content)
html <- wp_content$parse$text
View(html)
#Parse HTML
text=extractHTMLStrip(html)
text=str_replace_all(text,"\n", " ")
text=data.frame(text)
View(text)
twitteR:::setup_twitter_oauth(consumer_key,consumer_secret,access_token,access_secret)
library(httr)
# 1. Find OAuth settings for twitter:
#    https://dev.twitter.com/docs/auth/oauth
oauth_endpoints("twitter")
# 2. Register an application at https://apps.twitter.com/
#    Make sure to set callback url to "http://127.0.0.1:1410/"
#
#    Replace key and secret below
myapp <- oauth_app("twitter",
key = "TYrWFPkFAkn4G5BbkWINYw",
secret = "qjOkmKYU9kWfUFWmekJuu5tztE9aEfLbt26WlhZL8"
)
# 3. Get OAuth credentials
twitter_token <- oauth1.0_token(oauth_endpoints("twitter"), myapp)
devtools::install_github("mkearney/rtweet")
# 3. Get OAuth credentials
twitter_token <- oauth1.0_token(oauth_endpoints("twitter"), myapp)
twitteR:::setup_twitter_oauth(consumer_key,consumer_secret,access_token,access_secret)
library(base64enc)
install.packages("base64enc")
library(base64enc)
twitteR:::setup_twitter_oauth(consumer_key,consumer_secret,access_token,access_secret)
library(twitteR)
require("twitteR")
#Connect with Twitter API using below
options(httr_oauth_cache=T)
consumer_key    = 'SJeBNqqHTcjwg7PhWGYHljuvf'
consumer_secret = 'ZDauLdKLqBR5yWsG79jZsDjfABPm63eDknRL27h7OfoBS5IkT'
access_token    = '1035066840005787648-N1702KVt51nYA9s3f02RD51KkM2pOw'
access_secret   = 'eGD9Db6oqR8UklZkoitVofekG7ZJDvx00ni0jKMwJvYYU'
download.file(url="http://curl.haxx.se/ca/cacert.pem",destfile="cacert.pem")
twitteR:::setup_twitter_oauth(consumer_key,consumer_secret,access_token,access_secret)
setup_twitter_oauth(consumer_key,consumer_secret,access_token,access_secret)
check_replace <- str_replace_all(c(21,""," " ,34,"-",78, 98), c(" ", "", "-"), NA_character_)
replace(check_replace, " " , NA_character_)
check_replace <- replace(c(21,""," " ,34,"-",78, 98), c(" ", "", "-"), NA_character_)
check_replace
check_replace <- str_replace(c(21,""," " ,34,"-",78, 98), c(" ", "", "-"), NA_character_)
check_replace <- str_replace(c(21,""," " ,34,"-",78, 98), c(" ","", "-"), NA_character_)
check_replace <- str_replace(c(21,""," " ,34,"-",78, 98), c(""," ", "-"), NA_character_)
check_replace <- str_replace(c(21,""," " ,34,"-",78, 98), c(""," ", "-"), NA_character_)
check_replace <- str_replace(c(21,""," " ,34,"-",78, 98), c(" ", "", "-"), NA_character_)
check_replace <- as.numeric(check_replace)
check_replace <- as.numeric(c(21,""," " ,34,"-",78, 98))
check_replace <- str_replace(c(21,34,"99*",56,"90*", "45*"), "*", "")
check_replace <- replace(c(21,34,"99*",56,"90*", "45*"), "*", "")
check_replace <- as.numeric(c(21,34,99*,56,90*, 45*))
check_replace <- as.numeric(c(21,34,99*,56,90*, 45*))
test_vector <- c(21,34,"99*",56,"90*", "45*")
test1 <- gsub("*", "", test_vector)
test1 <- gsub("*", "", test_vector)
test_vector <- c(21,34,"99*",56,"90*", "45*")
test1 <- gsub("*", "", test_vector)
test_vector <- c(21,34,"99*",56,"90*", "45*")
test1 <- as.integer(test_vector)
test1 <- as.numeric(test_vector)
test1 <- sub(test_vector)
test1 <- sub(test_vector)
test1 <- sub("*", "", test_vector)
test1 <- gsub("[[:punct:]]", "", test_vector)
test1 <- as.numeric(gsub("[[:punct:]]", "", test_vector))
test1 <- is.na(test_vector > 100)
test_vector <- c(89, 90, 108, 56)
test1 <- is.na(test_vector > 100)
test_vector <- c(89, 90, 108, 56)
is.na(test_vector) <- test_vector > 100
df <- rbind(c(2,9,6),c(4,6,7),c(4,6,7),c(4,6,7),c(2,9,6))
View(df)
df <- unique(df[,])
View(df)
setwd("J:/Vatsa/IIITB_Data Analytics/Term 2/EDA_5")
# import data
uber_data <- read.csv("Uber Request Data.csv", stringsAsFactors = F)
str(uber_data)
library(stringr)
# Extract request hour
# Split the request time stamp colum and store in a data frame
uber_temp <- data.frame(cbind(str_split_fixed(uber_data$Request.timestamp, " ", 2)))
# My analysis is based on the request hour so removing unwanted rows
uber_temp <- uber_temp[-1]
# Store the request hour back into data frame
uber_data$reqhour <- as.numeric(format(strptime(uber_temp$X2,"%H:%M"), "%H"))
# Intent is to create an data frame which will store the request hours,
# total number of cars cancelled in each hour, total number of cars not available for each hour
# And most occuring place (Mode parameter) for both these instances
uber_aggregate <- uber_data[1:24, 1:6]
uber_aggregate[,] <- NA
colnames(uber_aggregate)[1:6] <- c("reqhour", "total_request", "cancel_cars", "cancel_point", "no_cars", "nocars_point")
# Function to find the most occuring location
Most_occur <- function(vect){
names(table(vect))[as.vector(table(vect))==max(table(vect))]
}
# Looping to find for each hour: the total requests,
# total canceled cars and most occuring location
# total non-availability of cars and most occuring location
for(i in 1:24)
{
# Update request hour
hour <- i-1
uber_aggregate$reqhour[i] <- hour
# Find the number of requests for each hour
uber_aggregate$total_request[i] <- sum(uber_data$reqhour == hour)
# Find the number of cancelled cars for each hour
uber_aggregate$cancel_cars[i] <- sum(uber_data$reqhour == hour & uber_data$Status == "Cancelled")
# Find the number of cars not available for each hour
uber_aggregate$no_cars[i] <- sum(uber_data$reqhour == hour & uber_data$Status == "No Cars Available")
# Find the most occuring cancel location (mode) for each hour
uber_aggregate$cancel_point[i] <- Most_occur(uber_data$Pickup.point[which(uber_data$reqhour == hour & uber_data$Status == "Cancelled")])
# Find the most occuring no cars location (mode) for each hour
uber_aggregate$nocars_point[i] <- Most_occur(uber_data$Pickup.point[which(uber_data$reqhour == hour & uber_data$Status == "No Cars Available")])
}
library(ggplot2)
View(uber_aggregate)
# to view the problem statement to understand how cancelled and No cars issue stand
ggplot(uber_aggregate, aes(x = reqhour, y = total_request, fill = Status)) + geom_bar() +
labs(title = "Idenitfy occcurence of most pressing problems over the Hour")
# to view the problem statement to understand how cancelled and No cars issue stand
ggplot(uber_data, aes(x = reqhour, fill = Status)) + geom_bar() +
labs(title = "Idenitfy occcurence of most pressing problems over the Hour")
write.csv(uber_aggregate, "check.csv")
Most_occur <- function(vect){
#names(table(vect))[as.vector(table(vect))==max(table(vect))]
uniqv <- unique(vect)
uniqv[which.max(tabulate(match(vect, uniqv)))]
}
# Looping to find for each hour: the total requests,
# total canceled cars and most occuring location
# total non-availability of cars and most occuring location
for(i in 1:24)
{
# Update request hour
hour <- i-1
uber_aggregate$reqhour[i] <- hour
# Find the number of requests for each hour
uber_aggregate$total_request[i] <- sum(uber_data$reqhour == hour)
# Find the number of cancelled cars for each hour
uber_aggregate$cancel_cars[i] <- sum(uber_data$reqhour == hour & uber_data$Status == "Cancelled")
# Find the number of cars not available for each hour
uber_aggregate$no_cars[i] <- sum(uber_data$reqhour == hour & uber_data$Status == "No Cars Available")
# Find the most occuring cancel location (mode) for each hour
uber_aggregate$cancel_point[i] <- Most_occur(uber_data$Pickup.point[which(uber_data$reqhour == hour & uber_data$Status == "Cancelled")])
# Find the most occuring no cars location (mode) for each hour
uber_aggregate$nocars_point[i] <- Most_occur(uber_data$Pickup.point[which(uber_data$reqhour == hour & uber_data$Status == "No Cars Available")])
}
